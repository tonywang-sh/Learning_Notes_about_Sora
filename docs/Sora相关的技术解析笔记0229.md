## Sora相关的技术解析笔记
#### 1. Sora的基本概念（Sora是什么）
Sora是由OpenAI最新发布的文生视频（T2V）模型，能够将文本描述转化为相应的视频内容。这意味着可以给Sora一个故事或场景描述，Sora都能转换为一段生动的视频。Sora不仅代表了数据处理和视频生成技术的重大突破，也显现了AI技术在理解和视觉内容创造方面的巨大潜力。

#### 2. Sora的功能边界(from OpenAI official report)
从OpenAI官方发布的Sora生成的视频看，Sora视频生成技术的三大亮点：“60秒超长长度”、“单视频多角度镜头”和“世界模型”，例如：
60秒超长长度：目前已有的T2V模型，例如pika、runway等还只能生成4秒长度的视频，Sora生成60秒视频的能力直接拉开了差距，而且动作连续、具有一定的艺术性或没有生硬的感觉；
单视频多角度镜头：在60秒的视频内，可以在保持主角色不变的高度一致性的同时，还生成多个角度的分镜；
世界模型： 从官方发布的演示视频中可以看出，Sora有时能够模拟对世界状态产生简单影响的行为。例如，画家可以在画布上持续添加新的笔触，或者一个人吃汉堡时留下咬痕等。

官方发布的演示视频具有以下的一些功能特点：
    1）最大支持60秒高清晰度视频生成，以及基于已有的短视频的前后扩展，同时保持任务/场景的高度一致性；
    2）超强的视频无缝融合能力；
    3）同一场景的多角度/镜头的生成能力；
    4）具有动态摄像机运动的视频，随着摄像机的移动和旋转，人和其他场景元素在三维空间中一致地移动；
    5）支持任意分辨率及宽高比的视频输出
    6）对物理规律的理解仍然十分有限

Sora能力总结：
  Text-to-video: 文生视频；
  Image-to-video: 图生视频；
  Video-to-video: 改变源视频风格or场景；
  Extending video in time: 视频拓展(前后双向)；
  Create seamless loops: Tiled videos that seem like they never end；
  Image generation: 图片生成 (size最高达到 2048 x 2048)；
  Generate video in any format: From 1920 x 1080 to 1080 x 1920 视频输出比例自定义；
  Simulate virtual worlds: 链接虚拟世界，游戏视频场景生成；
  Create a video: 长达60s的视频并保持人物、场景一致性；

#### 3. Sora潜在的关联技术
目前业界推测的Sora模型架构：
![image](https://github.com/tonywang-sh/Learning_Notes_about_Sora/assets/731029/9eb10f79-eab9-49f6-8727-a37c3ff8d0ab)
关联技术：Video Compression Network (Spacetime patches),DiT，NaViT, video re-caption, etc.
Sora的模型训练流程示例：
![image](https://github.com/tonywang-sh/Learning_Notes_about_Sora/assets/731029/9ee56bb8-95ba-4a24-9563-e00596b3ab47)


#### 4. Sora技术复现难点
目前复现Sora的技术存在多方面的难点瓶颈，例如训练数据、关联技术的核心关键部分的架构和训练、算力资源等。
后续潜在尝试的复现技术点：
   1）训练数据生成
   2）视频压缩网络，spacetime patches,训练等
   3）解决算力的有效利用等

#### 5. 相关参考
###### 【1】https://openai.com/research/video-generation-models-as-world-simulators
###### 【2】https://datawhaler.feishu.cn/wiki/LxSCw0EyRidru1kFkttc1jNQnnh
###### 【3】https://datawhaler.feishu.cn/file/KntHbV3QGoEPruxEql2c9lrsnOb
###### 【4】Sora A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models, 2024
